{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a58c837b",
   "metadata": {},
   "source": [
    "# Assignment 1 — N-Puzzle Project Code and Documentation\n",
    "\n",
    "This project was originally implemented as a collection of python scripts/modules as can be seen on https://github.com/antonnemch/CP468_Projects/\n",
    "It was compiled into this notebook for ease of submission, with one module per code cell. An overview of the documentation is found in the table of contents below, and more details can be found in the headers of specific files.\n",
    "\n",
    "## Table of Contents & Documentation\n",
    "\n",
    "1. requirements.txt  \n",
    "2. puzzle.py — Board implementation  \n",
    "3. heuristics.py — Heuristic functions (h₁–h₃)  \n",
    "4. search.py — A* search algorithm  \n",
    "5. metrics.py — Branching factor utilities  \n",
    "6. run_experiments.py — Experiment driver & visualization\n",
    "\n",
    "---\n",
    "\n",
    "## 1. requirements.txt\n",
    "\n",
    "**Required packages (brief):**\n",
    "\n",
    "- `matplotlib` — for plotting results and visualizations  \n",
    "- `numpy` — numeric helpers for heuristics and metrics  \n",
    "- `pandas` — tabular data, CSV output, experiment summaries  \n",
    "- `pytest` — testing framework for module correctness\n",
    "\n",
    "---\n",
    "\n",
    "## 2. puzzle.py\n",
    "\n",
    "> **Author:** Anton Nemchinski\n",
    "\n",
    "This module implements an **immutable**, **memory-efficient** representation of the sliding-tile n-puzzle and a small set of helpers used by the experiment harness.\n",
    "\n",
    "### Key Design Points\n",
    "- `Board` is a **frozen dataclass** with `slots=True` → immutable, hashable, lightweight.  \n",
    "- Tiles are stored as a **flat 1-D tuple** of length `n*n`, with `0` representing the blank.  \n",
    "- The blank index is cached in `zero` for efficient neighbor generation.  \n",
    "- All methods return **new `Board` instances** (no mutation).\n",
    "\n",
    "### API (At-a-Glance)\n",
    "- **`class Board(n, tiles, zero)`**\n",
    "  - `Board.goal(n)` → solved board  \n",
    "  - `Board.from_flat(n, flat)` → build board from sequence (validates input)  \n",
    "  - `Board.from_rows(rows)` → build board from nested lists  \n",
    "  - `Board.is_goal()` → check if solved  \n",
    "  - `Board.is_solvable()` → check solvability via inversion counts  \n",
    "  - `Board.visualize()` → ASCII multi-line view  \n",
    "  - `Board.neighbors()` → generate legal neighbor states (up to 4)  \n",
    "  - `Board.randomize(k, seed=None)` → produce reachable randomized board\n",
    "\n",
    "- **Helpers**\n",
    "  - `manual_move(board, direction)` → apply single U/D/L/R move  \n",
    "  - `manual_play(n=3, r=10)` → small interactive puzzle console\n",
    "\n",
    "---\n",
    "\n",
    "## 3. heuristics.py\n",
    "\n",
    "> **Author:** Julian Rincon\n",
    "\n",
    "Implements admissible heuristics for A*:\n",
    "\n",
    "- **h₁ Misplaced Tiles:** Number of misplaced non-blank tiles  \n",
    "- **h₂ Manhattan Distance:** Sum of Manhattan distances to goal positions  \n",
    "- **h₃ Linear Conflict:** Manhattan + 2×(linear conflicts), stronger but still admissible\n",
    "\n",
    "### API (At-a-Glance)\n",
    "- `_goal_pos_map(n)` → dict mapping tile → goal `(row, col)`  \n",
    "- `h1_misplaced(board)` → int  \n",
    "- `h2_manhattan(board)` → int  \n",
    "- `h3_linear_conflict(board)` → int\n",
    "\n",
    "---\n",
    "\n",
    "## 4. search.py\n",
    "\n",
    "> **Authors:** Roop Bassi, Jordan Franschman\n",
    "\n",
    "Straightforward **A\\*** search implementation. Focuses on clarity and correctness.\n",
    "\n",
    "- Stores `g`-values and parents for path reconstruction  \n",
    "- Uses a **heap** keyed by `f = g + h`  \n",
    "- Returns a `SearchResult` dataclass\n",
    "\n",
    "### API (At-a-Glance)\n",
    "- `SearchResult(solved, solution_depth, nodes_expanded, runtime, path)`  \n",
    "- `astar(board, heuristic)` → `SearchResult`\n",
    "\n",
    "> Includes a small demo when run as a script (random 3×3 board).\n",
    "\n",
    "---\n",
    "\n",
    "## 5. metrics.py\n",
    "\n",
    "> **Author:** Jordan Franschman\n",
    "\n",
    "Small utility module for **branching factor analysis**.\n",
    "\n",
    "### API (At-a-Glance)\n",
    "- `branching_factor(nodes_expanded, solution_depth, tolerance=0.01)` → float  \n",
    "  Solves for **b\\*** using binary search:\n",
    "  \\[\n",
    "  1 + b^* + (b^*)^2 + \\dots + (b^*)^d = \\text{nodes\\_expanded}\n",
    "  \\]\n",
    "\n",
    "Returns `0.0` for trivial cases.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. run_experiments.py\n",
    "\n",
    "> **Author:** Anton Nemchinski\n",
    "\n",
    "Experiment driver & visualization utilities.\n",
    "\n",
    "- Runs A* on randomized puzzles with multiple heuristics  \n",
    "- Collects & summarizes results using pandas  \n",
    "- Generates comparison tables, CSVs, and plots\n",
    "\n",
    "### API (At-a-Glance)\n",
    "- `run_single_experiment(n, num_moves, seed, h_funcs)`  \n",
    "- `run_multiple_experiments(n, num_moves, num_experiments, h_funcs)`  \n",
    "- `calculate_statistics(results)` → DataFrame  \n",
    "- `create_and_save_comparison_table(...)` → CSV + DataFrame  \n",
    "- `save_image_table_nodes_and_bf(...)` → PNG table & CSV  \n",
    "- `save_comparison_graphs(...)` → scatter/line plots  \n",
    "- `ensure_figures_directory(n)` → directory path  \n",
    "- `run_part_1/2/3()` → run experiments for 8-, 15-, and 24-puzzle\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660a874a",
   "metadata": {},
   "source": [
    "## 1. requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8617f080",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf7db2",
   "metadata": {},
   "source": [
    "## 2. puzzle.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843fbb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"n-puzzle Board implementation and utilities.\n",
    "\n",
    "This module implements an immutable, memory-efficient representation of the n-puzzle\n",
    "(sliding tile puzzle) and a small set of helpers used by the experimental harness.\n",
    "\n",
    "Author\n",
    "------\n",
    "Anton Nemchinski\n",
    "\n",
    "Key design points\n",
    "-----------------\n",
    "- Board instances are immutable (a frozen dataclass with ``slots=True``). This makes\n",
    "    them hashable and cheap to copy by reference when used as keys in dictionaries or\n",
    "    sets (useful for search algorithms).\n",
    "- The board is stored as a flat 1-D tuple ``tiles`` of length ``n*n`` where the\n",
    "    blank tile is represented by 0. The index of the blank is cached in ``zero`` for\n",
    "    fast neighbor generation.\n",
    "- Methods return new ``Board`` objects instead of mutating state. The module\n",
    "    provides convenience constructors and utilities for testing and interactive use.\n",
    "\n",
    "API (at-a-glance)\n",
    "------------------\n",
    "- class Board(n, tiles, zero):\n",
    "    - Board.goal(n) -> Board\n",
    "        Return solved board for size n. O(n^2) time to construct.\n",
    "    - Board.from_flat(n, flat) -> Board\n",
    "        Validate and return board from flat sequence. O(n^2).\n",
    "    - Board.from_rows(rows) -> Board\n",
    "        Build board from nested list.\n",
    "    - Board.is_goal() -> bool\n",
    "        True if board equals goal state. O(1) tuple comparison.\n",
    "    - Board.is_solvable() -> bool\n",
    "        Determine solvability using inversion counts (standard rule). O(n^2).\n",
    "    - Board.visualize() -> str\n",
    "        Return an ASCII multi-line representation for printing. O(n^2).\n",
    "    - Board.neighbors() -> Iterator[Board]\n",
    "        Yield neighbor boards by sliding the blank. Generates up to 4 neighbors. O(n^2)\n",
    "        per neighbor creation (cost copies the tile tuple).\n",
    "    - Board.randomize(k, seed=None) -> Board\n",
    "        Produce a board reachable from this one after k random legal moves.\n",
    "\n",
    "- module-level helpers:\n",
    "    - manual_move(board, direction) -> Board\n",
    "        Apply a single move 'U','D','L','R' to the given board (raises if illegal).\n",
    "    - manual_play(n=3, r=10)\n",
    "        Small interactive console to play the puzzle (helpful for manual testing).\n",
    "\n",
    "Examples\n",
    "\n",
    "        >>> b = Board.goal(3)\n",
    "        >>> print(b.visualize())\n",
    "         1  2  3\n",
    "         4  5  6\n",
    "         7  8  X\n",
    "\n",
    "        # randomize 10 legal moves from the goal (deterministic with seed)\n",
    "        >>> r = b.randomize(10, seed=42)\n",
    "\n",
    "Notes\n",
    "-----\n",
    "- All random scrambles generated by :meth:`randomize` are reachable from the goal\n",
    "    (and therefore solvable) because they are produced by applying legal moves to\n",
    "    the goal state.\n",
    "- The :meth:`is_solvable` method implements standard inversion-count rules for\n",
    "    determining solvability.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Iterator, Tuple, List, Optional, Sequence\n",
    "import random\n",
    "\n",
    "# Main Board Class\n",
    "@dataclass(frozen=True, slots=True)\n",
    "class Board:\n",
    "    \"\"\"\n",
    "    Immutable n-puzzle board.\n",
    "    tiles: flattened tuple of length n*n with 0 as the blank.\n",
    "    zero: index of the blank in tiles (cached for speed).\n",
    "    \"\"\"\n",
    "    n: int\n",
    "    tiles: Tuple[int, ...]\n",
    "    zero: int\n",
    "\n",
    "    # Constructors ####################################################\n",
    "    @staticmethod\n",
    "    def goal(n: int) -> \"Board\":\n",
    "        \"\"\"Return the solved n×n board: (1..n*n-1,0).\"\"\"\n",
    "        flat = tuple(range(1, n * n)) + (0,)\n",
    "        return Board(n, flat, flat.index(0))\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_flat(n: int, flat: Sequence[int]) -> \"Board\":\n",
    "        \"\"\"Build a board from a flat sequence of length n*n.\"\"\"\n",
    "        flat = tuple(flat)\n",
    "        if len(flat) != n*n:\n",
    "            raise ValueError(...)\n",
    "        if set(flat) != set(range(n*n)):\n",
    "            raise ValueError(...)\n",
    "        return Board(n, flat, flat.index(0))\n",
    "\n",
    "    @staticmethod\n",
    "    def from_rows(rows: List[List[int]]) -> \"Board\":\n",
    "        \"\"\"Build a board from a square list-of-lists. Validates shape and contents.\"\"\"\n",
    "        n = len(rows)\n",
    "        flat = tuple(x for row in rows for x in row)\n",
    "        return Board.from_flat(n, flat)\n",
    "    \n",
    "    # Methods #########################################################\n",
    "    def is_goal(self) -> bool:\n",
    "        \"\"\"True if this board is the solved state.\"\"\"\n",
    "        # Compare tuples directly (fast).\n",
    "        return self.tiles == Board.goal(self.n).tiles\n",
    "\n",
    "    def is_solvable(self) -> bool:\n",
    "        \"\"\"\n",
    "        Calculates disorder parameter (inversions) to determine if the board is solvable.\n",
    "        - Odd n: solvable iff inversions even.\n",
    "        - Even n: solvable iff (inversions + blank_row_from_bottom) is odd.\n",
    "        \"\"\"\n",
    "        n = self.n\n",
    "        arr = [x for x in self.tiles if x != 0]\n",
    "        inv = 0\n",
    "        for i in range(len(arr)):\n",
    "            ai = arr[i]\n",
    "            inv += sum(1 for j in range(i + 1, len(arr)) if arr[j] < ai)\n",
    "\n",
    "        if n % 2 == 1:\n",
    "            return inv % 2 == 0\n",
    "        else:\n",
    "            row_from_bottom = n - (self.zero // n)  # 1-based\n",
    "            return (inv + row_from_bottom) % 2 == 1\n",
    "\n",
    "    def visualize(self) -> str:\n",
    "        \"\"\"ASCII grid; blank as spaces.\"\"\"\n",
    "        n = self.n\n",
    "        rows = [self.tiles[i : i + n] for i in range(0, n * n, n)]\n",
    "        return \"\\n\".join(\n",
    "            \" \".join(f\"{x:2d}\" if x != 0 else \" X\" for x in row) for row in rows\n",
    "        )\n",
    "\n",
    "\n",
    "    def neighbors(self) -> Iterator[\"Board\"]:\n",
    "        \"\"\"\n",
    "        Yield all legal boards by sliding the blank up/down/left/right.\n",
    "        Deterministic order: Up, Down, Left, Right.\n",
    "        \"\"\"\n",
    "        n, z = self.n, self.zero\n",
    "        r, c = divmod(z, n)\n",
    "        deltas = []\n",
    "        if r > 0:     deltas.append(-n)  # Up\n",
    "        if r < n - 1: deltas.append(+n)  # Down\n",
    "        if c > 0:     deltas.append(-1)  # Left\n",
    "        if c < n - 1: deltas.append(+1)  # Right\n",
    "\n",
    "        t = self.tiles\n",
    "        for d in deltas:\n",
    "            nz = z + d\n",
    "            lst = list(t)\n",
    "            lst[z], lst[nz] = lst[nz], lst[z]\n",
    "            yield Board(n, tuple(lst), nz)\n",
    "\n",
    "\n",
    "    # Utilities #######################################################\n",
    "    def randomize(self, k: int, seed: Optional[int] = None) -> \"Board\":\n",
    "        \"\"\"\n",
    "        Return a new board reached by k random legal blank moves.\n",
    "        Avoids immediate backtracking when possible. Always solvable.\n",
    "        \"\"\"\n",
    "        rng = random.Random(seed)\n",
    "        b = self\n",
    "        prev_tiles: Tuple[int, ...] | None = None\n",
    "        for _ in range(k):\n",
    "            nbrs = list(b.neighbors())\n",
    "            if prev_tiles is not None and len(nbrs) > 1:\n",
    "                nbrs = [x for x in nbrs if x.tiles != prev_tiles]\n",
    "            prev_tiles = b.tiles\n",
    "            b = rng.choice(nbrs)\n",
    "        return b\n",
    "    \n",
    "def manual_move(b: Board, direction: str) -> Board:\n",
    "    \"\"\"\n",
    "    Return a new board by sliding the blank in the given direction.\n",
    "    Direction is one of \"U\", \"D\", \"L\", \"R\" (case-insensitive).\n",
    "    Raises ValueError if the move is illegal.\n",
    "    \"\"\"\n",
    "    direction = direction.upper()\n",
    "    n, z = b.n, b.zero\n",
    "    r, c = divmod(z, n)\n",
    "    if direction == \"U\":\n",
    "        if r == 0:\n",
    "            raise ValueError(\"Illegal move Up\")\n",
    "        d = -n\n",
    "    elif direction == \"D\":\n",
    "        if r == n - 1:\n",
    "            raise ValueError(\"Illegal move Down\")\n",
    "        d = +n\n",
    "    elif direction == \"L\":\n",
    "        if c == 0:\n",
    "            raise ValueError(\"Illegal move Left\")\n",
    "        d = -1\n",
    "    elif direction == \"R\":\n",
    "        if c == n - 1:\n",
    "            raise ValueError(\"Illegal move Right\")\n",
    "        d = +1\n",
    "    else:\n",
    "        raise ValueError(\"Direction must be one of U,D,L,R\")\n",
    "\n",
    "    nz = z + d\n",
    "    lst = list(b.tiles)\n",
    "    lst[z], lst[nz] = lst[nz], lst[z]\n",
    "    return Board(n, tuple(lst), nz)\n",
    "\n",
    "def manual_play(n: int = 3,r: int = 10) -> None:\n",
    "    \"\"\"\n",
    "    Simple interactive console play of the puzzle.\n",
    "    Commands: U,D,L,R to move; Q to quit; R to randomize; H for help.\n",
    "    \"\"\"\n",
    "    print(\"Welcome to the n-puzzle! Commands: U,D,L,R to move; Q to quit; R to randomize; H for help.\")\n",
    "    board = Board.goal(n).randomize(r, seed=42)\n",
    "    while True:\n",
    "        print(\"\\nCurrent board:\")\n",
    "        print(board.visualize())\n",
    "        if board.is_goal():\n",
    "            print(\"Congratulations! You've solved the puzzle!\")\n",
    "            break\n",
    "        cmd = input(\"Enter command (U/D/L/R/Q/R/H): \").strip().upper()\n",
    "        if cmd == \"Q\":\n",
    "            print(\"Thanks for playing!\")\n",
    "            break\n",
    "        elif cmd == \"H\":\n",
    "            print(\"Commands: U,D,L,R to move; Q to quit; R to randomize; H for help.\")\n",
    "        elif cmd == \"R\":\n",
    "            board = Board.goal(n).randomize(10)\n",
    "            print(\"Board randomized.\")\n",
    "        elif cmd in (\"U\", \"D\", \"L\", \"R\"):\n",
    "            try:\n",
    "                board = manual_move(board, cmd)\n",
    "            except ValueError as e:\n",
    "                print(e)\n",
    "        else:\n",
    "            print(\"Invalid command. Type H for help.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e8ab72",
   "metadata": {},
   "source": [
    "## 3. heuristics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d7969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Heuristic functions for the n-puzzle.\n",
    "\n",
    "This module provides admissible heuristics used by the A* search driver:\n",
    "- h1_misplaced: number of misplaced tiles (ignore blank)\n",
    "- h2_manhattan: sum of Manhattan distances to goal positions\n",
    "- h3_linear_conflict: Manhattan + 2 * (linear conflict pairs)\n",
    "\n",
    "Author\n",
    "------\n",
    "Julian Rincon\n",
    "\n",
    "API (at-a-glance)\n",
    "------------------\n",
    "- _goal_pos_map(n) -> Dict[int, (row, col)]\n",
    "    Map tile value to its goal coordinates (excludes blank).\n",
    "- h1_misplaced(board: Board) -> int\n",
    "    Count of non-blank tiles not in goal position. O(n^2).\n",
    "- h2_manhattan(board: Board) -> int\n",
    "    Sum of Manhattan distances for all tiles. O(n^2).\n",
    "- h3_linear_conflict(board: Board) -> int\n",
    "    Manhattan plus linear conflict correction; admissible and\n",
    "    typically stronger than Manhattan. O(n^2) with a small constant.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "from typing import Tuple, Dict\n",
    "# from puzzle import Board\n",
    "\n",
    "def _goal_pos_map(n: int) -> Dict[int, Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Map each tile value -> (goal_row, goal_col).\n",
    "    Tile 0 (blank) is excluded.\n",
    "    Goal layout is (1..n*n-1, 0).\n",
    "    \"\"\"\n",
    "    m: Dict[int, Tuple[int, int]] = {}\n",
    "    for v in range(1, n * n):\n",
    "        r, c = divmod(v - 1, n)\n",
    "        m[v] = (r, c)\n",
    "    return m\n",
    "\n",
    "def h1_misplaced(board: Board) -> int:\n",
    "    \"\"\"Number of tiles not in their goal position (ignore blank).\"\"\"\n",
    "    return sum(\n",
    "        1\n",
    "        for i, v in enumerate(board.tiles)\n",
    "        if v != 0 and i != (v - 1)\n",
    "    )\n",
    "\n",
    "def h2_manhattan(board: Board) -> int:\n",
    "    \"\"\"Sum of Manhattan distances of each tile from its goal position.\"\"\"\n",
    "    n = board.n\n",
    "    goal = _goal_pos_map(n)\n",
    "    dist = 0\n",
    "    for i, v in enumerate(board.tiles):\n",
    "        if v == 0:\n",
    "            continue\n",
    "        r, c = divmod(i, n)\n",
    "        gr, gc = goal[v]\n",
    "        dist += abs(r - gr) + abs(c - gc)\n",
    "    return dist\n",
    "# Helper function for h3\n",
    "def _linear_conflicts_in_line(line_vals, line_index, is_row, goal):\n",
    "    \"\"\"\n",
    "    Count linear conflicts among tiles in one row/column.\n",
    "    - Only tiles whose goal row (or column) is this line are considered.\n",
    "    - A pair (a,b) is in conflict if both belong to this line in goal,\n",
    "      but their order is reversed relative to goal columns (or rows).\n",
    "    Returns the count of *conflicting pairs* (each adds +2 to heuristic).\n",
    "    \"\"\"\n",
    "    conflicts = 0\n",
    "    seq = []\n",
    "    for idx_along, v in enumerate(line_vals):\n",
    "        if v == 0:\n",
    "            continue\n",
    "        gr, gc = goal[v]\n",
    "        if is_row:\n",
    "            if gr == line_index:\n",
    "                seq.append((idx_along, gc))\n",
    "        else:\n",
    "            if gc == line_index:\n",
    "                seq.append((idx_along, gr))\n",
    "    \n",
    "    for i in range(len(seq)):\n",
    "        for j in range(i + 1, len(seq)):\n",
    "            if seq[i][1] > seq[j][1]:\n",
    "                conflicts += 1\n",
    "    return conflicts\n",
    "\n",
    "def h3_linear_conflict(board: Board) -> int:\n",
    "    \"\"\"\n",
    "    Linear Conflict heuristic:\n",
    "      h = Manhattan + 2 * (# of linear-conflict pairs in rows and columns)\n",
    "    Admissible and consistent; stronger than pure Manhattan.\n",
    "    \"\"\"\n",
    "    n = board.n\n",
    "    goal = _goal_pos_map(n)\n",
    "    man = h2_manhattan(board)\n",
    "\n",
    "    # Row \n",
    "    row_conflicts = 0\n",
    "    for r in range(n):\n",
    "        start = r * n\n",
    "        row_vals = board.tiles[start : start + n]\n",
    "        row_conflicts += _linear_conflicts_in_line(row_vals, r, True, goal)\n",
    "\n",
    "    # Column\n",
    "    col_conflicts = 0\n",
    "    for c in range(n):\n",
    "        col_vals = board.tiles[c : n * n : n]\n",
    "        col_conflicts += _linear_conflicts_in_line(col_vals, c, False, goal)\n",
    "\n",
    "    return man + 2 * (row_conflicts + col_conflicts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a30345f",
   "metadata": {},
   "source": [
    "## 4. search.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf6fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A* search implementation and a simple SearchResult container.\n",
    "\n",
    "This module provides a straightforward A* implementation used by the\n",
    "experiment harness. It focuses on clarity and correctness rather than\n",
    "performance micro-optimizations. The A* implementation stores g-values,\n",
    "parents for path reconstruction, and uses a heap keyed by f = g + h.\n",
    "\n",
    "Authors\n",
    "-------\n",
    "Roop Bassi\n",
    "Jordan Franschman\n",
    "\n",
    "API (at-a-glance)\n",
    "------------------\n",
    "- dataclass SearchResult(solved, solution_depth, nodes_expanded, runtime, path)\n",
    "    Container returned by :func:`astar` describing the outcome.\n",
    "- astar(board, heuristic) -> SearchResult\n",
    "    Run A* from the given start board using the provided heuristic function\n",
    "    (callable taking a Board and returning an int). Returns a SearchResult.\n",
    "\n",
    "Note: This module includes a small demo that runs A* on a randomized 3x3\n",
    "board when executed as a script. Remove or guard demo code if embedding in\n",
    "larger systems.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#import heuristics, puzzle\n",
    "from heapq import heappush, heappop\n",
    "from itertools import count\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    solved: bool\n",
    "    solution_depth: int\n",
    "    nodes_expanded: int\n",
    "    runtime: float\n",
    "    path: Optional[List] = None\n",
    "\n",
    "def astar(board, heuristic):\n",
    "    # record start time\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    heap = []\n",
    "    nodes_expanded = 0\n",
    "    g_values = {board.tiles: 0}\n",
    "    parent = {board.tiles: None}  #track parents for path\n",
    "    tie_counter = count() # need this in case of a tie so it doesn't check next element\n",
    "\n",
    "    # Push f(n) = h(n)+0, g(n), tie_counter, board\n",
    "    heappush(heap, (heuristic(board), 0, next(tie_counter), board))\n",
    "\n",
    "    while heap:\n",
    "        f, g, tie, board = heappop(heap)\n",
    "\n",
    "        if g_values.get(board.tiles, 1000000000000000) < g:\n",
    "            continue\n",
    "\n",
    "        nodes_expanded += 1\n",
    "\n",
    "        if board.is_goal():\n",
    "            path = []\n",
    "            current = board\n",
    "            while current is not None:\n",
    "                path.append(current)\n",
    "                current = parent.get(current.tiles)\n",
    "            path.reverse()\n",
    "            \n",
    "            runtime = time.perf_counter() - start_time\n",
    "            return SearchResult(True, g, nodes_expanded, runtime, path)\n",
    "\n",
    "        for neighbour in board.neighbors():\n",
    "            total_g = g + 1\n",
    "            if total_g < g_values.get(neighbour.tiles, 1000000000000000):\n",
    "                g_values[neighbour.tiles] = total_g\n",
    "                parent[neighbour.tiles] = board  # Track parent\n",
    "                fn = total_g + heuristic(neighbour)\n",
    "                heappush(heap, (fn, total_g, next(tie_counter), neighbour))\n",
    "                \n",
    "    runtime = time.perf_counter()-start_time  # calculate runtime\n",
    "    return SearchResult(False, -1, nodes_expanded, runtime, None)  # CHANGE THIS\n",
    "\n",
    "\n",
    "board = Board.goal(3).randomize(15, seed=42)\n",
    "print(board)\n",
    "\n",
    "res_h1 = astar(board, h1_misplaced)\n",
    "print(f'Solved: {res_h1.solved}\\nTotal Steps:{res_h1.solution_depth}\\nNodes Expanded: {res_h1.nodes_expanded}\\nRuntime: {res_h1.runtime:.4f}s\\n')\n",
    "\n",
    "res_h2 = astar(board, h2_manhattan)\n",
    "print(f'Solved: {res_h2.solved}\\nTotal Steps:{res_h2.solution_depth}\\nNodes Expanded: {res_h2.nodes_expanded}\\nRuntime: {res_h2.runtime:.4f}s\\n')\n",
    "\n",
    "res_h3 = astar(board, h3_linear_conflict)\n",
    "print(f'Solved: {res_h3.solved}\\nTotal Steps:{res_h3.solution_depth}\\nNodes Expanded: {res_h3.nodes_expanded}\\nRuntime: {res_h3.runtime:.4f}s\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38b94ec",
   "metadata": {},
   "source": [
    "## 5. metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f186a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Metrics utilities for analyzing search behavior.\n",
    "\n",
    "Currently this module exposes a single utility used by the experiment\n",
    "driver to compute the effective branching factor (b*), the branching\n",
    "factor that would produce the observed number of expanded nodes at a\n",
    "given solution depth in a uniform tree.\n",
    "\n",
    "Author\n",
    "------\n",
    "Jordan Franschman\n",
    "\n",
    "API (at-a-glance)\n",
    "------------------\n",
    "- branching_factor(nodes_expanded: int, solution_depth: int, tolerance: float = 0.01) -> float\n",
    "  Numerically solve for b* in the equation: 1 + b* + b*^2 + ... + b*^d = nodes_expanded\n",
    "  using binary search. Returns 0.0 for trivial cases.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def branching_factor(nodes_expanded: int, solution_depth: int, tolerance: float = 0.01) -> float:\n",
    "\n",
    "    if solution_depth == 0 or nodes_expanded <= 1:\n",
    "        return 0.0\n",
    "    \n",
    "    low,high = 1.0, float(nodes_expanded)\n",
    "    \n",
    "    while high-low > tolerance:\n",
    "        mid = (low + high) / 2.0\n",
    "      \n",
    "        if abs(mid - 1.0) < 1e-9:\n",
    "            total = solution_depth + 1\n",
    "        else:\n",
    "            total = (mid**(solution_depth + 1) - 1) / (mid - 1)\n",
    "        \n",
    "        if total < nodes_expanded:\n",
    "            low = mid\n",
    "        else:\n",
    "            high = mid\n",
    "    \n",
    "    return (low + high) / 2.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a998efc",
   "metadata": {},
   "source": [
    "## 6. run_experiments.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae49dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Experiment driver and visualization utilities for the n-puzzle project.\n",
    "\n",
    "This module orchestrates experiments that run A* with multiple heuristics\n",
    "across different puzzle sizes, collects results, computes summaries, and\n",
    "produces CSVs and figures organized under a Results/PartX directory layout.\n",
    "\n",
    "Author\n",
    "------\n",
    "Anton Nemchinski\n",
    "\n",
    "API (at-a-glance)\n",
    "------------------\n",
    "- run_single_experiment(n, num_moves, seed, h_funcs) -> Dict[str, SearchResult]\n",
    "    Run A* on a single randomized instance for all heuristics provided.\n",
    "- run_multiple_experiments(n, num_moves, num_experiments, h_funcs)\n",
    "    Produce results for many instances; prints progress and returns a dict\n",
    "    mapping heuristic name -> list of SearchResult.\n",
    "- calculate_statistics(results) -> pd.DataFrame\n",
    "    Aggregate per-heuristic statistics (mean nodes, depth, runtime, b*, success_rate).\n",
    "- create_and_save_comparison_table(results, n, base_path) -> pd.DataFrame\n",
    "    Save a CSV comparing nodes expanded and branching factor per solution depth.\n",
    "- save_image_table_nodes_and_bf(results, n, base_path) -> pd.DataFrame\n",
    "    Produce the PNG table visual used in reports and a CSV summary.\n",
    "- save_comparison_graphs(results, n, base_path)\n",
    "    Save scatter and line plots (nodes vs depth, branching factor vs depth).\n",
    "- ensure_figures_directory(n) -> str\n",
    "    Create Results/PartX directories and return the path appropriate for n.\n",
    "- run_part_1/2/3()\n",
    "    Runners for 8-, 15-, and 24-puzzle experiments respectively. Each returns\n",
    "    the raw results dict for that part.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Callable\n",
    "\n",
    "\n",
    "# Project modules\n",
    "# from puzzle import Board\n",
    "# from search import astar, SearchResult\n",
    "# import heuristics\n",
    "# from metrics import branching_factor\n",
    "\n",
    "\n",
    "def save_image_table_nodes_and_bf(results: Dict[str, List[SearchResult]], n: int, base_path: str):\n",
    "    \"\"\"Generate and save an image table like the textbook, for nodes and branching factor by depth and heuristic.\"\"\"\n",
    "    depth_groups = defaultdict(lambda: defaultdict(list))\n",
    "    for h_name, h_results in results.items():\n",
    "        for result in h_results:\n",
    "            if result.solved:\n",
    "                depth_groups[result.solution_depth][h_name].append(result)\n",
    "    heuristics = list(results.keys())\n",
    "    table_data = []\n",
    "    for d in sorted(depth_groups.keys()):\n",
    "        row = [d]\n",
    "        # Nodes expanded for each heuristic\n",
    "        for h_name in heuristics:\n",
    "            vals = [r.nodes_expanded for r in depth_groups[d].get(h_name, [])]\n",
    "            row.append(int(np.mean(vals)) if vals else '')\n",
    "        # Branching factor for each heuristic\n",
    "        for h_name in heuristics:\n",
    "            vals = [branching_factor(r.nodes_expanded, r.solution_depth) for r in depth_groups[d].get(h_name, [])]\n",
    "            row.append(round(np.mean(vals), 2) if vals else '')\n",
    "        table_data.append(row)\n",
    "    # Build column headers\n",
    "    col_labels = [\"d\"] + [f\"{h} Nodes\" for h in heuristics] + [f\"{h} BF\" for h in heuristics]\n",
    "    # Adjust figure size to fit table tightly\n",
    "    fig_height = 0.6 * len(table_data) + 1.8\n",
    "    fig_width = max(2 + 2 * len(heuristics), 8)\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "    ax.axis('off')\n",
    "    tbl = ax.table(cellText=table_data, colLabels=col_labels, loc='center', cellLoc='center')\n",
    "    for col_idx in range(len(col_labels)):\n",
    "        tbl.auto_set_column_width(col=col_idx)\n",
    "    tbl.auto_set_font_size(False)\n",
    "    tbl.set_fontsize(11)\n",
    "    tbl.scale(1.1, 1.1)\n",
    "    # Style header row\n",
    "    for (row, col), cell in tbl.get_celld().items():\n",
    "        if row == 0:\n",
    "            cell.set_fontsize(12)\n",
    "            cell.set_text_props(weight='bold')\n",
    "            cell.set_facecolor('#e0e0e0')\n",
    "        # Remove cell borders for a cleaner look\n",
    "        cell.set_linewidth(0.5)\n",
    "    # Center the table title and reduce whitespace\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(left=0.08, right=0.92, top=0.82, bottom=0.08)\n",
    "    plt.title(f\"A* Search Cost and Branching Factor ({n}x{n} Puzzle)\", fontsize=14, pad=10)\n",
    "    plt.savefig(f\"{base_path}/table_nodes_bf_{n}x{n}.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.close()\n",
    "    # import matplotlib.ticker as ticker\n",
    "    depth_groups = defaultdict(lambda: defaultdict(list))\n",
    "    for h_name, h_results in results.items():\n",
    "        for result in h_results:\n",
    "            if result.solved:\n",
    "                depth_groups[result.solution_depth][h_name].append(result.nodes_expanded)\n",
    "    table_data = []\n",
    "    heuristics = list(results.keys())\n",
    "    for d in sorted(depth_groups.keys()):\n",
    "        row = {'d': d}\n",
    "        for h_name in heuristics:\n",
    "            vals = depth_groups[d].get(h_name, [])\n",
    "            row[h_name] = int(np.mean(vals)) if vals else ''\n",
    "        table_data.append(row)\n",
    "    df = pd.DataFrame(table_data)\n",
    "    df.to_csv(f'{base_path}/summary_nodes_by_depth_{n}x{n}.csv', index=False)\n",
    "    return df\n",
    "\n",
    "def run_single_experiment(n: int, num_moves: int, seed: int, \n",
    "                         h_funcs: Dict[str, Callable]) -> Dict[str, SearchResult]:\n",
    "    \"\"\"Run experiment for a single puzzle instance with all heuristics.\"\"\"\n",
    "    board = Board.goal(n).randomize(num_moves, seed=seed)\n",
    "    results = {}\n",
    "    \n",
    "    for h_name, h_func in h_funcs.items():\n",
    "        result = astar(board, h_func)\n",
    "        results[h_name] = result\n",
    "        \n",
    "    return results\n",
    "\n",
    "def run_multiple_experiments(n: int, num_moves: int, num_experiments: int,\n",
    "                           h_funcs: Dict[str, Callable]) -> Dict[str, List[SearchResult]]:\n",
    "    \"\"\"Run multiple experiments and collect results.\"\"\"\n",
    "    results = defaultdict(list)\n",
    "    \n",
    "    for seed in range(num_experiments):\n",
    "        single_results = run_single_experiment(n, num_moves, seed, h_funcs)\n",
    "        for h_name, result in single_results.items():\n",
    "            results[h_name].append(result)\n",
    "        if (seed + 1) % 10 == 0 or (seed + 1) == num_experiments:\n",
    "            print(f\"  Completed {seed + 1}/{num_experiments} experiments...\")\n",
    "    return dict(results)\n",
    "\n",
    "def calculate_statistics(results: Dict[str, List[SearchResult]]) -> pd.DataFrame:\n",
    "    \"\"\"Calculate statistics from experimental results.\"\"\"\n",
    "    stats = {}\n",
    "    \n",
    "    for h_name, h_results in results.items():\n",
    "        solved_results = [r for r in h_results if r.solved]\n",
    "        if not solved_results:\n",
    "            continue\n",
    "            \n",
    "        stats[h_name] = {\n",
    "            'solution_depth_mean': int(np.mean([r.solution_depth for r in solved_results])),\n",
    "            'nodes_expanded_mean': int(np.mean([r.nodes_expanded for r in solved_results])),\n",
    "            'runtime_mean': np.mean([r.runtime for r in solved_results]).round(4),\n",
    "            'branching_factor': np.mean([\n",
    "                branching_factor(r.nodes_expanded, r.solution_depth) \n",
    "                for r in solved_results\n",
    "            ]).round(3),\n",
    "            'success_rate': round(len(solved_results) / len(h_results), 3)\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame(stats).round(3)\n",
    "\n",
    "def create_and_save_comparison_table(results: Dict[str, List[SearchResult]], n: int, base_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Create and save a detailed comparison table.\"\"\"\n",
    "    depth_groups = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    for h_name, h_results in results.items():\n",
    "        for result in h_results:\n",
    "            if result.solved:\n",
    "                depth_groups[result.solution_depth][h_name].append(result)\n",
    "    \n",
    "    table_data = []\n",
    "    for d in sorted(depth_groups.keys()):\n",
    "        row = {'Solution Depth': d}\n",
    "        for h_name, results_at_depth in depth_groups[d].items():\n",
    "            nodes = np.mean([r.nodes_expanded for r in results_at_depth])\n",
    "            bf = np.mean([\n",
    "                branching_factor(r.nodes_expanded, r.solution_depth)\n",
    "                for r in results_at_depth\n",
    "            ])\n",
    "            row[f'{h_name} Nodes Expanded'] = int(nodes)\n",
    "            row[f'{h_name} Branching Factor'] = round(bf, 2)\n",
    "        table_data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(table_data)\n",
    "    # Save as CSV only\n",
    "    df.to_csv(f'{base_path}/comparison_table_{n}x{n}.csv', index=False)\n",
    "    return df\n",
    "\n",
    "def analyze_heuristic_domination(results: Dict[str, List[SearchResult]]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze whether heuristics dominate each other.\n",
    "    A heuristic h1 dominates h2 if:\n",
    "    1. h1 expands fewer or equal nodes for all problems\n",
    "    2. h1 expands strictly fewer nodes for at least one problem\n",
    "    \"\"\"\n",
    "    heuristics = list(results.keys())\n",
    "    domination_data = []\n",
    "    \n",
    "    for h1 in heuristics:\n",
    "        for h2 in heuristics:\n",
    "            if h1 == h2:\n",
    "                continue\n",
    "                \n",
    "            # Match problems by solution depth for fair comparison\n",
    "            h1_by_depth = defaultdict(list)\n",
    "            h2_by_depth = defaultdict(list)\n",
    "            \n",
    "            for r in results[h1]:\n",
    "                if r.solved:\n",
    "                    h1_by_depth[r.solution_depth].append(r.nodes_expanded)\n",
    "            for r in results[h2]:\n",
    "                if r.solved:\n",
    "                    h2_by_depth[r.solution_depth].append(r.nodes_expanded)\n",
    "                    \n",
    "            common_depths = set(h1_by_depth.keys()) & set(h2_by_depth.keys())\n",
    "            if not common_depths:\n",
    "                continue\n",
    "                \n",
    "            dominates = True\n",
    "            strict_dominance = False\n",
    "            \n",
    "            for depth in common_depths:\n",
    "                h1_nodes = np.mean(h1_by_depth[depth])\n",
    "                h2_nodes = np.mean(h2_by_depth[depth])\n",
    "                \n",
    "                if h1_nodes > h2_nodes:\n",
    "                    dominates = False\n",
    "                    break\n",
    "                if h1_nodes < h2_nodes:\n",
    "                    strict_dominance = True\n",
    "                    \n",
    "            if dominates and strict_dominance:\n",
    "                domination_data.append({\n",
    "                    'dominating': h1,\n",
    "                    'dominated': h2,\n",
    "                    'common_problems': len(common_depths)\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(domination_data)\n",
    "\n",
    "def save_comparison_graphs(results: Dict[str, List[SearchResult]], n: int, base_path: str):\n",
    "    \"\"\"Create and save comparison graphs for the results.\"\"\"\n",
    "    # Nodes vs Depth Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for h_name, h_results in results.items():\n",
    "        solved_results = [r for r in h_results if r.solved]\n",
    "        if not solved_results:\n",
    "            continue\n",
    "            \n",
    "        depths = [r.solution_depth for r in solved_results]\n",
    "        nodes = [r.nodes_expanded for r in solved_results]\n",
    "        plt.scatter(depths, nodes, label=h_name, alpha=0.5)\n",
    "    \n",
    "    plt.xlabel('Solution Depth')\n",
    "    plt.ylabel('Nodes Expanded')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.title(f'{n}x{n} Puzzle: Solution Depth vs Nodes Expanded')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'{base_path}/nodes_vs_depth_{n}x{n}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Branching Factor Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    depths = defaultdict(lambda: defaultdict(list))\n",
    "    for h_name, h_results in results.items():\n",
    "        for r in h_results:\n",
    "            if r.solved:\n",
    "                bf = branching_factor(r.nodes_expanded, r.solution_depth)\n",
    "                depths[r.solution_depth][h_name].append(bf)\n",
    "    \n",
    "    for h_name in results.keys():\n",
    "        x = sorted(depths.keys())\n",
    "        y = [np.mean(depths[d][h_name]) for d in x if depths[d][h_name]]\n",
    "        plt.plot(x, y, marker='o', label=h_name)\n",
    "    \n",
    "    plt.xlabel('Solution Depth')\n",
    "    plt.ylabel('Effective Branching Factor')\n",
    "    plt.title(f'{n}x{n} Puzzle: Effective Branching Factor vs Solution Depth')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'{base_path}/branching_factor_{n}x{n}.png')\n",
    "    plt.close()\n",
    "\n",
    "def ensure_figures_directory(n=None):\n",
    "    \"\"\"Create Part1, Part2, Part3 directories if they don't exist and return the correct one for n.\"\"\"\n",
    "    import os\n",
    "    parent_dir = \"Results\"\n",
    "    if not os.path.exists(parent_dir):\n",
    "        os.makedirs(parent_dir)\n",
    "    if n == 3:\n",
    "        part_dir = os.path.join(parent_dir, \"Part1\")\n",
    "    elif n == 4:\n",
    "        part_dir = os.path.join(parent_dir, \"Part2\")\n",
    "    elif n == 5:\n",
    "        part_dir = os.path.join(parent_dir, \"Part3\")\n",
    "    else:\n",
    "        part_dir = os.path.join(parent_dir, \"figures\")\n",
    "    if not os.path.exists(part_dir):\n",
    "        os.makedirs(part_dir)\n",
    "    return part_dir\n",
    "\n",
    "def run_part_1():\n",
    "    # Run experiments for 8-puzzle\n",
    "    \"\"\"Run experiments for 8-puzzle.\"\"\"\n",
    "    \"\"\"Run experiments for 8-puzzle.\"\"\"\n",
    "    print(\"\\n=== Part 1: 8-puzzle Experiments ===\")\n",
    "    n = 3  # 8-puzzle is 3x3\n",
    "    h_funcs = {\n",
    "        'h1 (Misplaced)': h1_misplaced,\n",
    "        'h2 (Manhattan)': h2_manhattan,\n",
    "        'h3 (Linear Conflict)': h3_linear_conflict\n",
    "    }\n",
    "    \n",
    "    results = run_multiple_experiments(n, num_moves=20, num_experiments=100, h_funcs=h_funcs)\n",
    "    figures_dir = ensure_figures_directory(n)\n",
    "    \n",
    "    print(\"\\nStatistics:\")\n",
    "    stats = calculate_statistics(results)\n",
    "    print(stats)\n",
    "    stats.to_csv(f'{figures_dir}/statistics_8puzzle.csv')\n",
    "    \n",
    "    print(\"\\nDetailed Performance Comparison by Solution Depth:\")\n",
    "    comparison = create_and_save_comparison_table(results, n, figures_dir)\n",
    "    print(comparison)\n",
    "    \n",
    "    print(\"\\nHeuristic Domination Analysis:\")\n",
    "    domination = analyze_heuristic_domination(results)\n",
    "    print(domination)\n",
    "    domination.to_csv(f'{figures_dir}/domination_8puzzle.csv')\n",
    "    \n",
    "    save_comparison_graphs(results, n, figures_dir)\n",
    "    # Export all raw results for each heuristic\n",
    "    for h_name, h_results in results.items():\n",
    "        pd.DataFrame([\n",
    "            {\n",
    "                'solved': r.solved,\n",
    "                'solution_depth': r.solution_depth,\n",
    "                'nodes_expanded': r.nodes_expanded,\n",
    "                'runtime': r.runtime\n",
    "            } for r in h_results\n",
    "        ]).to_csv(f'{figures_dir}/raw_results_{h_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")}_8puzzle.csv', index=False)\n",
    "    # Save PNG table at the end\n",
    "    save_image_table_nodes_and_bf(results, n, figures_dir)\n",
    "    return results\n",
    "\n",
    "def run_part_2():\n",
    "    # Run experiments for 15-puzzle\n",
    "    \"\"\"Run experiments for 15-puzzle.\"\"\"\n",
    "    \"\"\"Run experiments for 15-puzzle.\"\"\"\n",
    "    print(\"\\n=== Part 2: 15-puzzle Experiments ===\")\n",
    "    n = 4  # 15-puzzle is 4x4\n",
    "    h_funcs = {\n",
    "        'h1 (Misplaced)': h1_misplaced,\n",
    "        'h2 (Manhattan)': h2_manhattan,\n",
    "        'h3 (Linear Conflict)': h3_linear_conflict\n",
    "    }\n",
    "    \n",
    "    results = run_multiple_experiments(n, num_moves=20, num_experiments=100, h_funcs=h_funcs)\n",
    "    figures_dir = ensure_figures_directory(n)\n",
    "    \n",
    "    print(\"\\nStatistics:\")\n",
    "    stats = calculate_statistics(results)\n",
    "    print(stats)\n",
    "    stats.to_csv(f'{figures_dir}/statistics_15puzzle.csv')\n",
    "    \n",
    "    print(\"\\nDetailed Performance Comparison by Solution Depth:\")\n",
    "    comparison = create_and_save_comparison_table(results, n, figures_dir)\n",
    "    print(comparison)\n",
    "    \n",
    "    print(\"\\nHeuristic Domination Analysis:\")\n",
    "    domination = analyze_heuristic_domination(results)\n",
    "    print(domination)\n",
    "    domination.to_csv(f'{figures_dir}/domination_15puzzle.csv')\n",
    "    \n",
    "    save_comparison_graphs(results, n, figures_dir)\n",
    "    # Export all raw results for each heuristic\n",
    "    for h_name, h_results in results.items():\n",
    "        pd.DataFrame([\n",
    "            {\n",
    "                'solved': r.solved,\n",
    "                'solution_depth': r.solution_depth,\n",
    "                'nodes_expanded': r.nodes_expanded,\n",
    "                'runtime': r.runtime\n",
    "            } for r in h_results\n",
    "        ]).to_csv(f'{figures_dir}/raw_results_{h_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")}_15puzzle.csv', index=False)\n",
    "    # Save PNG table at the end\n",
    "    save_image_table_nodes_and_bf(results, n, figures_dir)\n",
    "    return results\n",
    "\n",
    "def run_part_3():\n",
    "    # Run experiments for 24-puzzle\n",
    "    \"\"\"Run experiments for 24-puzzle.\"\"\"\n",
    "    \"\"\"Run experiments for 24-puzzle.\"\"\"\n",
    "    print(\"\\n=== Part 3: 24-puzzle Experiments ===\")\n",
    "    n = 5  # 24-puzzle is 5x5\n",
    "    h_funcs = {\n",
    "        'h1 (Misplaced)': h1_misplaced,\n",
    "        'h2 (Manhattan)': h2_manhattan,\n",
    "        'h3 (Linear Conflict)': h3_linear_conflict\n",
    "    }\n",
    "    \n",
    "    results = run_multiple_experiments(n, num_moves=20, num_experiments=100, h_funcs=h_funcs)\n",
    "    figures_dir = ensure_figures_directory(n)\n",
    "    \n",
    "    print(\"\\nStatistics:\")\n",
    "    stats = calculate_statistics(results)\n",
    "    print(stats)\n",
    "    stats.to_csv(f'{figures_dir}/statistics_24puzzle.csv')\n",
    "    \n",
    "    print(\"\\nDetailed Performance Comparison by Solution Depth:\")\n",
    "    comparison = create_and_save_comparison_table(results, n, figures_dir)\n",
    "    print(comparison)\n",
    "    \n",
    "    print(\"\\nHeuristic Domination Analysis:\")\n",
    "    domination = analyze_heuristic_domination(results)\n",
    "    print(domination)\n",
    "    domination.to_csv(f'{figures_dir}/domination_24puzzle.csv')\n",
    "    \n",
    "    save_comparison_graphs(results, n, figures_dir)\n",
    "    # Export all raw results for each heuristic\n",
    "    for h_name, h_results in results.items():\n",
    "        pd.DataFrame([\n",
    "            {\n",
    "                'solved': r.solved,\n",
    "                'solution_depth': r.solution_depth,\n",
    "                'nodes_expanded': r.nodes_expanded,\n",
    "                'runtime': r.runtime\n",
    "            } for r in h_results\n",
    "        ]).to_csv(f'{figures_dir}/raw_results_{h_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")}_24puzzle.csv', index=False)\n",
    "    # Save PNG table at the end\n",
    "    save_image_table_nodes_and_bf(results, n, figures_dir)\n",
    "    return results\n",
    "\n",
    "def compare_all_results(results_8: dict, results_15: dict, results_24: dict):\n",
    "    \"\"\"Create unified comparison of all puzzle sizes.\"\"\"\n",
    "    print(\"\\n=== Unified Comparison Across Puzzle Sizes ===\")\n",
    "    \n",
    "    sizes = {3: results_8, 4: results_15, 5: results_24}\n",
    "    \n",
    "    for n, results in sizes.items():\n",
    "        print(f\"\\n{n}x{n} Puzzle Statistics:\")\n",
    "        print(calculate_statistics(results))\n",
    "    \n",
    "    # Create combined visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "    \n",
    "    for idx, (n, results) in enumerate(sizes.items()):\n",
    "        for h_name, h_results in results.items():\n",
    "            solved_results = [r for r in h_results if r.solved]\n",
    "            if not solved_results:\n",
    "                continue\n",
    "                \n",
    "            depths = [r.solution_depth for r in solved_results]\n",
    "            nodes = [r.nodes_expanded for r in solved_results]\n",
    "            \n",
    "            axes[idx].scatter(depths, nodes, label=h_name, alpha=0.5)\n",
    "        \n",
    "        axes[idx].set_xlabel('Solution Depth')\n",
    "        axes[idx].set_ylabel('Nodes Expanded')\n",
    "        axes[idx].set_yscale('log')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].set_title(f'{n}x{n} Puzzle')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run all experiments\n",
    "    results_8 = run_part_1()\n",
    "    results_15 = run_part_2()\n",
    "    results_24 = run_part_3()\n",
    "    \n",
    "    # Show unified comparison\n",
    "    compare_all_results(results_8, results_15, results_24)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
